# -HAMD-ME
Human Action Monitoring Dataset in Manufacturing Enviroments

## Description
The dataset was generated on a workstation with three cameras to capture multimodal data. 
The recordings take at the Human Factors Laboratory of the School of Industrial Engineering.   
All captures are recorded simultaneously and synchronized to facilitate multimodal data analysis. 

The dataset is composed of video captures of 3 views while a person performs wiring tasks. A camera has been placed in the top view, side view, and front view.

The top and side views take using Logitech C310 cameras. The front camera is a Microsoft HD camera. 
All cameras used are high-definition cameras with autozoom. The quality of the videos is 1280 x 720 pixels with a frame rate of 30 frames per second. All videos have no audio.

The dataset was build involving male and female participants. All the videos show the assembly and disassembly operations of the product shown .
The Assembly consists of 3 gears, 3 shafts, 8 sinkers, nuts, and bolts. 

In the top view the following has been captured: hands, tools, and items to assemble the product. In this view we have also labeled the following actions:

1. Hold
2. Release
3. Screw

These actions are performed with all the tools. 
The tools used in the experiments are the following:

1. Wrench
2. Allen Key
3. Ratchet
4. Screwdriver

In the side view, the skeleton of the person has been labeled, where it is possible to analyze the posture of the person when executing the actions.

In the front view there is a capture of the person's face, where it is possible to analyze if the person shows signs of fatigue while performing the work
